<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Methods · BLO Hub</title>
  <meta name="description" content="Solution methods for bilevel optimization: classical, evolutionary algorithms, ML-based methods, and hybrids." />

  <!-- MathJax (optional for inline math, not required for this page but handy) -->
  <script>
    window.MathJax = { tex: { tags: 'ams', tagSide: 'right', tagIndent: '0.8em' } };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- <link rel="stylesheet" href="assets/style.css" /> -->
</head>

<body>
  <header class="topbar">
    <div class="container topbar-inner">
      <a class="brand" href="index.html">BLO Hub</a>
      <nav class="nav">
        <a class="navlink" href="index.html">Home</a>
        <a class="navlink" href="taxonomy.html">Taxonomy</a>
        <a class="navlink" href="formulation.html">Formulations</a>
        <a class="navlink active" href="methods.html">Methods</a>
        <a class="navlink" href="papers.html">Papers</a>
        <a class="navlink" href="#references">References</a>
      </nav>
      <button class="menuBtn" id="menuBtn" aria-label="Toggle menu">☰</button>
    </div>

    <div class="mobileNav container" id="mobileNav">
      <a href="index.html">Home</a>
      <a class="navlink" href="taxonomy.html">Taxonomy</a>
      <a href="formulation.html">Formulations</a>
      <a href="methods.html">Methods</a>
      <a href="papers.html">Papers</a>
      <a href="#references">References</a>
    </div>
  </header>

  <main class="container section">
    <div class="pageHead">
      <div>
        <h1>Solution Methods</h1>
        <p class="muted">
          A practical organization of BLO solution approaches: <strong>Classical</strong>, <strong>Evolutionary Algorithms</strong>,
          <strong>Machine Learning</strong>, and <strong>Hybrid EA–ML</strong>.
        </p>
      </div>
      <div class="rightTools">
        <a class="btn" href="papers.html">Browse papers</a>
      </div>
    </div>

    <div class="grid2">
      <div class="card">
        <h2 id="classical">Classical methods</h2>
        <p>
          Classical approaches exploit analytical structure to reduce bilevel problems to single-level forms or to solve them exactly in
          restricted settings. They are most effective when the problem has a clear mathematical form (e.g., linear/convex/quadratic),
          with assumptions such as continuity/differentiability and regularity conditions at the lower level
          <a href="#ref-anandalingam1992hierarchical" class="cite">[3]</a>,
          <a href="#ref-colson2007overview" class="cite">[4]</a>.
        </p>
         <p class="muted small">
          Practical note: if the LL is nonconvex, discrete, nonsmooth, or available only through a simulator/legacy solver, classical guarantees may not apply,
          and one typically needs approximations (e.g., penalties, trust regions, or zeroth-order hypergradients) or derivative-free methods.
        </p>

        <hr/>

        <h3>Single-level reduction via KKT conditions (KKT/MPEC)</h3>
        <p>
          When the LL problem is convex and satisfies constraint qualifications, the LL can be replaced by its KKT optimality conditions.
          This yields a single-level formulation (often an MPEC), but introduces complementarity constraints that can be difficult to handle
          <a href="#ref-sinha2018review" class="cite">[1]</a>,
          <a href="#ref-bard1998practical" class="cite">[5]</a>.
        </p>

        <div class="equation"><div class="math">
\begin{equation}\label{eq:classical-ll}
\begin{aligned}
\mathbf{y}^*(\mathbf{x}) \in \arg\min_{\mathbf{y}} \quad & f(\mathbf{x},\mathbf{y})\\
\text{s.t.}\quad & g(\mathbf{x},\mathbf{y})\le 0.
\end{aligned}
\end{equation}
        </div></div>

        <p class="muted small"><strong>KKT replacement (typical):</strong></p>
        <div class="equation"><div class="math">
\begin{equation}\label{eq:classical-kkt}
\begin{aligned}
\nabla_{\mathbf{y}} f(\mathbf{x},\mathbf{y}) + \nabla_{\mathbf{y}} g(\mathbf{x},\mathbf{y})^\top \boldsymbol{\lambda} &= 0,\\
g(\mathbf{x},\mathbf{y}) \le 0,\quad \boldsymbol{\lambda}\ge 0,\quad 
\boldsymbol{\lambda}\odot g(\mathbf{x},\mathbf{y}) &= 0.
\end{aligned}
\end{equation}
        </div></div>

        <p class="muted small">
          In linear bilevel classes, this pathway often leads to MILP-style reformulations (e.g., via linearization of complementarity),
          which can then be solved with branch-and-bound (B&B) on small-to-medium structured instances
          <a href="#ref-bard1998practical" class="cite">[5]</a>.
        </p>

        <hr/>

        <h3>Descent methods (hypergradient-based classical schemes)</h3>
        <p>
          Descent methods seek directions that improve the UL objective while respecting that the LL must remain optimal.
          In smooth settings (e.g., nonconvex-strongly-convex bilevel), hypergradients can be obtained by implicit differentiation or by
          controlled approximation of the LL solution mapping
          <a href="#ref-ghadimi2018approximation" class="cite">[6]</a>.
        </p>

        <div class="equation"><div class="math">
\begin{equation}\label{eq:classical-hypergradient}
\begin{aligned}
\nabla_{\mathbf{x}} \,F(\mathbf{x},\mathbf{y}^*(\mathbf{x}))
&= \nabla_{\mathbf{x}}F(\mathbf{x},\mathbf{y})
+ \nabla_{\mathbf{y}}F(\mathbf{x},\mathbf{y}) \cdot \frac{d\mathbf{y}^*(\mathbf{x})}{d\mathbf{x}},\\[2pt]
\frac{d\mathbf{y}^*(\mathbf{x})}{d\mathbf{x}}
&= - \left[\nabla_{\mathbf{y}\mathbf{y}}^2 f(\mathbf{x},\mathbf{y}^*)\right]^{-1}\nabla_{\mathbf{x}\mathbf{y}}^2 f(\mathbf{x},\mathbf{y}^*) \quad (\text{typical strong-convex LL}).
\end{aligned}
\end{equation}
        </div></div>

        <p class="muted small">
          These ideas connect directly to modern differentiable BLO (implicit gradients/unrolling),
          but classical variants emphasize algorithmic safeguards (feasibility maintenance, subproblem checks, and step control).
        </p>

        <hr/>

        <h3>Trust-region methods</h3>
        <p>
          Trust-region strategies build local models (approximations) of the bilevel objective inside a neighborhood (“trust region”),
          expanding or shrinking the region depending on how accurately the local model predicts real improvement
          <a href="#ref-yuan2015trust" class="cite">[12]</a>.
          In bilevel settings, trust-region ideas can be combined with variational inequality (VI) views of the LL or stabilized approximations of the LL response
          <a href="#ref-colson2005trustregion" class="cite">[13]</a>,
          <a href="#ref-colson2007overview" class="cite">[4]</a>.
        </p>

        <hr/>

        <h3>Penalty function methods</h3>
        <p>
          Penalty methods incorporate LL constraints or optimality conditions into the UL objective using penalty terms,
          creating a single-level approximation solvable by standard constrained optimization toolchains.
          Modern first-order penalty frameworks for bilevel optimization provide convergence guarantees under smoothness assumptions
          <a href="#ref-lu2023penalty" class="cite">[9]</a>,
          while early bilevel penalty ideas appear in Stackelberg formulations and double-penalty constructions
          <a href="#ref-aiyoshi1984penalty" class="cite">[10]</a>,
          <a href="#ref-ishizuka1992double" class="cite">[11]</a>.
        </p>

        <div class="equation"><div class="math">
\begin{equation}\label{eq:classical-penalty}
\min_{\mathbf{x},\mathbf{y}} \quad F(\mathbf{x},\mathbf{y}) \;+\; \rho \,\Phi(\mathbf{x},\mathbf{y}),
\end{equation}
        </div></div>
        <p class="muted small">
          where \(\Phi\) penalizes LL infeasibility and/or LL suboptimality (or KKT residuals), and \(\rho\) is increased to enforce the LL conditions.
        </p>

        <hr/>

        <h3>Zeroth-order (black-box) bilevel methods</h3>
        <p>
          In many practical BLO settings (e.g., simulators, privacy-restricted learning, legacy solvers), gradients are unavailable and only noisy
          function evaluations of \(F(\mathbf{x},\mathbf{y})\) and \(f(\mathbf{x},\mathbf{y})\) can be queried.
          Recent fully zeroth-order bilevel methods estimate (hyper)gradients using smoothing-based estimators and then perform principled bilevel updates
          with oracle-complexity guarantees in smooth regimes
          <a href="#ref-aghasi2025fully" class="cite">[7]</a>,
          <a href="#ref-aghasi2025optimal" class="cite">[8]</a>.
        </p>

        <p class="muted small"><strong>Typical smoothing estimator (illustrative):</strong></p>
        <div class="equation"><div class="math">
\begin{equation}\label{eq:classical-zo}
\widehat{\nabla} F(\mathbf{x})
= \frac{d}{\mu}\left(F(\mathbf{x}+\mu \mathbf{u})-F(\mathbf{x})\right)\mathbf{u},
\qquad \mathbf{u}\sim \mathcal{N}(0,I),
\end{equation}
        </div></div>

        <p class="muted small">
          These methods complement EA-style black-box solvers by adding theory in smooth settings; EAs can remain preferable when the landscape is nonsmooth,
          discrete, heavily constrained, or highly rugged.
        </p>
        <p class="muted small">
          Strength: strong guarantees on structured instances. Weakness: can fail or become impractical with nonconvexity, nonsmoothness, discreteness, or black-box LL solvers.
        </p>
      </div>

     <div class="card">
  <h2 id="ea">Evolutionary algorithms (EAs)</h2>

  <p>
    Due to the limitations of classical approaches, evolutionary algorithms (EAs) have become widely used for BLO
    <a href="#ref-turgut2023systematic" class="cite">[14]</a>.
    These population-based, derivative-free methods are particularly effective for non-convex, multi-modal, noisy, or black-box settings
    <a href="#ref-7942105" class="cite">[1]</a>,
    <a href="#ref-10121701" class="cite">[16]</a>.
    EA-based BLO methods differ mainly in how they (i) handle the LL optimization, (ii) reuse structure or information across levels, and
    (iii) control the computational cost of nested evaluations.
  </p>

  <hr/>

  <h3>Taxonomy and common EA frameworks for BLO</h3>
  <p class="muted">
    The central difficulty is the LL “response mapping”: each UL candidate may require solving one (or many) LL problems. EA frameworks
    trade off generality vs. computational cost by choosing how explicitly they solve, approximate, or co-evolve the LL response.
  </p>

  <h4>1) Nested EA</h4>
  <p>
    <strong>Idea:</strong> run an EA at the UL, and for each UL candidate, run a full EA at the LL to compute the follower response
    <a href="#ref-sinha2014finding" class="cite">[17]</a>,
    <a href="#ref-kuo2011hybrid" class="cite">[18]</a>.
  </p>
  <ul class="bullets">
    <li><strong>LL handling:</strong> explicit LL optimization (EA inside EA).</li>
    <li><strong>Strength:</strong> fully derivative-free; works for black-box/simulation-based LLs.</li>
    <li><strong>Limitation:</strong> extremely expensive, LL evaluations dominate runtime, especially at high dimensions or costly simulations
      <a href="#ref-li2024bridging" class="cite">[19]</a>,
      <a href="#ref-acm-3638530-3648409" class="cite">[20]</a>.
    </li>
  </ul>

  <h4>2) Single-level reduction + EA</h4>
  <p>
    <strong>Idea:</strong> reduce the bilevel model to a single-level constrained problem (often via KKT/MPEC-style conditions) and then solve it with EAs
    <a href="#ref-li2023ga" class="cite">[21]</a>,
    <a href="#ref-camacho2022tabu" class="cite">[22]</a>,
    <a href="#ref-10899879" class="cite">[23]</a>.
    This can improve efficiency but relies on assumptions (e.g., convexity, smoothness, valid constraint qualifications), which may not hold in noisy or
    simulator-based settings
    <a href="#ref-yang2024bilevel" class="cite">[24]</a>,
    <a href="#ref-lachhwani2022comprehensive" class="cite">[25]</a>.
  </p>
  <ul class="bullets">
    <li><strong>LL handling:</strong> implicit (encoded as constraints/conditions).</li>
    <li><strong>Strength:</strong> avoids repeated LL solves; often faster when assumptions hold.</li>
    <li><strong>Limitation:</strong> reformulations can be brittle; complementarity constraints can be hard to handle robustly.</li>
  </ul>

  <h4>3) Co-evolutionary EAs</h4>
  <p>
    <strong>Idea:</strong> evolve two interacting populations simultaneously, one for UL (leader) solutions and one for LL (follower) responses, so both levels
    adapt together
    <a href="#ref-chaabani2018new" class="cite">[26]</a>,
    <a href="#ref-8425468" class="cite">[27]</a>.
    Co-evolution can explore multiple follower responses without fully solving the LL from scratch for every UL candidate.
  </p>
  <ul class="bullets">
    <li><strong>LL handling:</strong> approximate via an evolving follower population.</li>
    <li><strong>Strength:</strong> parallelizable; can maintain diverse LL responses (helpful when LL optima are non-unique).</li>
    <li><strong>Limitation:</strong> coordination/synchronization matters, poor coupling may cause instability or premature convergence.</li>
  </ul>

  <h4>4) Surrogate-assisted EAs</h4>
  <p>
    <strong>Idea:</strong> learn surrogate models (e.g., GP/RBF/NN) to approximate expensive LL evaluations (objective/constraints or response mapping), and use
    surrogates during the EA search to reduce cost
    <a href="#ref-islam2017surrogate" class="cite">[28]</a>.
    Reliability depends on surrogate fidelity; practical designs often add uncertainty-aware sampling and periodic true re-evaluation.
  </p>
  <p class="muted small">
    <strong>Remark:</strong> Surrogate-assisted EAs sit at the interface of EA and ML. The surrogate is an ML component, but the overall solver is still
    evolutionary, so many surveys categorize them under EA-based BLO (and sometimes also as early EA-ML hybrids)
    <a href="#ref-colson2007overview" class="cite">[4]</a>,
    <a href="#ref-dempe2002foundations" class="cite">[29]</a>.
  </p>

  <hr/>

  <h3>Representative evolutionary bilevel advances (post-2018)</h3>
  <p>
    Recent EA research emphasizes: (i) better scalability to higher-dimensional BLO, (ii) reducing nested LL cost via reuse/transfer/parallelism, and
    (iii) surrogate learning or candidate preselection for expensive LL responses. Representative directions include response-approximation ideas
    (e.g., BLEAQ)
    <a href="#ref-sinha2017_bleaq" class="cite">[30]</a>,
    CMA-ES-style bilevel search with distribution sharing
    <a href="#ref-8388227" class="cite">[31]</a>,
    and transfer-learning-based parallel bilevel EAs (e.g., TLEA)
    <a href="#ref-9476019" class="cite">[32]</a>.
    Multiobjective and cooperative variants have also been explored
    <a href="#ref-9721406" class="cite">[33]</a>.
  </p>

  <hr/>

  <h3>Strengths and limitations</h3>
  <ul class="bullets">
    <li><strong>Strengths:</strong> derivative-free; handles discrete/mixed variables; robust to nonconvexity and black-box evaluations; easy to parallelize.</li>
    <li><strong>Limitations:</strong> high cost in nested settings; sample-inefficiency; sensitivity to parameters; scaling challenges in high dimensions; LL non-uniqueness can cause unstable UL decisions.</li>
  </ul>

  <hr/>

  <h3>Summary table</h3>
  <div style="overflow:auto">
    <table style="width:100%; border-collapse:collapse">
      <thead>
        <tr>
          <th style="text-align:left; padding:8px; border-bottom:1px solid rgba(0,0,0,0.12)">Approach</th>
          <th style="text-align:left; padding:8px; border-bottom:1px solid rgba(0,0,0,0.12)">LL handling</th>
          <th style="text-align:left; padding:8px; border-bottom:1px solid rgba(0,0,0,0.12)">Scalability</th>
          <th style="text-align:left; padding:8px; border-bottom:1px solid rgba(0,0,0,0.12)">Gradient use</th>
          <th style="text-align:left; padding:8px; border-bottom:1px solid rgba(0,0,0,0.12)">Typical use cases</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Nested EA</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Direct EA solve at LL</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Poor</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">No</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">General-purpose, black-box functions</td>
        </tr>
        <tr>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Single-level reduction + EA</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">KKT/MPEC-style constraints</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Moderate</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Yes*</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Convex/smooth LL; structured constrained forms</td>
        </tr>
        <tr>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Co-evolutionary EAs</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Two interacting populations</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Moderate</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">No</td>
          <td style="padding:8px; border-bottom:1px solid rgba(0,0,0,0.08)">Strategic/competitive interaction; multiple LL optima</td>
        </tr>
        <tr>
          <td style="padding:8px;">Surrogate-assisted EA</td>
          <td style="padding:8px;">Surrogate of LL or response mapping</td>
          <td style="padding:8px;">High</td>
          <td style="padding:8px;">No/Optional</td>
          <td style="padding:8px;">Expensive LL evaluations; simulator-driven BLO</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="muted small">*: only when required by the reformulation.</p>
</div>


    <div class="grid2">
      <div class="card">
        <h2 id="ml">Machine learning based methods</h2>
        <p>
          ML-based BLO approaches have grown rapidly due to automatic differentiation, larger datasets, and the need for scalable optimization pipelines
          <a href="#ref-zhang2023introductionbileveloptimizationfoundations" class="cite">[2]</a>.
        </p>
        <ul class="bullets">
          <li><strong>Differentiable bilevel optimization</strong>: implicit differentiation or unrolled optimization for gradient-based updates.</li>
          <li><strong>Surrogate modeling</strong>: learn approximate mappings (e.g., UL→LL response) to reduce LL solve cost.</li>
          <li><strong>RL / policy optimization</strong>: bilevel structure appears in meta-learning and hyperparameter tuning.</li>
        </ul>
        <p class="muted small">
          Strength: scalability on suitable classes. Weakness: assumptions (smoothness, differentiability, stable unrolling) may not hold for many discrete or black-box settings.
        </p>
      </div>

      <div class="card">
        <h2 id="hybrid">Hybrid EA–ML</h2>
        <p>
          Hybrid strategies aim to combine the robustness of EAs with the efficiency of learning-based components. Common hybrid patterns:
        </p>
        <ul class="bullets">
          <li><strong>EA + learned surrogate</strong> for LL objective/constraints or response mapping.</li>
          <li><strong>EA + differentiable components</strong> for partially-structured problems (mixed discrete/continuous).</li>
          <li><strong>Adaptive algorithm selection</strong> (bandits / meta-learning) to choose operators or LL solver effort.</li>
        </ul>
        <p class="muted small">
          Goal: reduce LL evaluation cost while keeping good global exploration.
        </p>
      </div>
    </div>

    <div class="card" id="example">
      <h2>Example: Toll setting in transportation systems</h2>
      <p class="muted small">
        Adapted from a common illustrative example (you can keep a footnote-style link for the public explanation).
      </p>

      <p>
        A government chooses toll values \(\mathbf{x}\) to maximize toll revenue \(F(\mathbf{x}, \mathbf{y})\), where \(\mathbf{y}\) denotes the resulting traffic flow.
        Travelers respond by selecting routes that minimize their travel cost \(f(\mathbf{x}, \mathbf{y})\) (including tolls and travel time).
        The UL models revenue maximization, while the LL captures user equilibrium / route choice under network constraints.
        This illustrates the nested leader–follower structure typical of BLO.
      </p>

      <p class="muted small">
        Public explainer link:
        <a class="link" href="https://en.wikipedia.org/wiki/Bilevel_optimization" target="_blank" rel="noreferrer">Wikipedia: Bilevel optimization</a>
      </p>
    </div>

    <section class="container section" id="references" style="padding:0">
      <div class="card">
        <h2>References</h2>
        <ol class="refs">
          <li id="ref-7942105">
            A. Sinha, P. Malo, and K. Deb, “A Review on Bilevel Optimization: From Classical to Evolutionary Approaches and Applications,”
            <i>IEEE Transactions on Evolutionary Computation</i>, vol. 22, no. 2, pp. 276–295, 2018, doi: 10.1109/TEVC.2017.2712906.
          </li>

          <li id="ref-zhang2023introductionbileveloptimizationfoundations">
            Y. Zhang et al., “An introduction to bilevel optimization: Foundations and applications in signal processing and machine learning,”
            <i>IEEE Signal Processing Magazine</i>, vol. 41, no. 1, pp. 38–59, 2024.
          </li>

          <!-- Added for "Classical methods" -->
          <li id="ref-anandalingam1992hierarchical">
            G. Anandalingam and T. Friesz, “Hierarchical optimization: an introduction,” <i>Annals of Operations Research</i>, vol. 34, pp. 1–11, 1992.
          </li>

          <li id="ref-colson2007overview">
            B. Colson, P. Marcotte, and G. Savard, “An overview of bilevel optimization,” <i>Annals of Operations Research</i>, vol. 153, pp. 235–256, 2007.
          </li>

          <li id="ref-bard1998practical">
            J. F. Bard, <i>Practical Bilevel Optimization: Algorithms and Applications</i>, Kluwer Academic Publishers, 1998.
          </li>

          <li id="ref-ghadimi2018approximation">
            S. Ghadimi and M. Wang, “Approximation Methods for Bilevel Programming,” arXiv:1802.02246, 2018.
          </li>

          <li id="ref-aghasi2025fully">
            A. Aghasi and S. Ghadimi, “Fully Zeroth-Order Bilevel Programming via Gaussian Smoothing,” <i>Journal of Optimization Theory and Applications</i>, vol. 205, no. 2, 2025.
          </li>

          <li id="ref-aghasi2025optimal">
            A. Aghasi, J. Umenberger, M. Alizadeh, H. Sun, and Z. Lu, “Optimal Zeroth-Order Bilevel Optimization,” arXiv:2510.03646, 2025.
          </li>

          <li id="ref-lu2023penalty">
            Z. Lu and S. Mei, “First-Order Penalty Methods for Bilevel Optimization,” arXiv:2311.07491, 2023.
          </li>

          <li id="ref-aiyoshi1984penalty">
            E. Aiyoshi and K. Shimizu, “A solution method for the static constrained Stackelberg problem via penalty method,”
            <i>IEEE Transactions on Automatic Control</i>, vol. 29, pp. 1111–1114, 1984.
          </li>

          <li id="ref-ishizuka1992double">
            Y. Ishizuka and E. Aiyoshi, “Double penalty method for bilevel optimization problems,” <i>Annals of Operations Research</i>, vol. 34, pp. 73–88, 1992.
          </li>

          <li id="ref-yuan2015trust">
            Y.-x. Yuan, “Recent advances in trust region algorithms,” <i>Mathematical Programming</i>, Ser. B, vol. 151, pp. 249–281, 2015.
          </li>

          <li id="ref-colson2005trustregion">
            B. Colson, P. Marcotte, and G. Savard, “A trust region method for nonlinear bilevel programming,”
            <i>Operations Research Letters</i>, vol. 33, no. 2, pp. 141–149, 2005.
          </li>

          <li id="ref-turgut2023systematic">
  Turgut et al., “(Systematic review on evolutionary bilevel optimization),” 2023. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-chauhan2024competitive">
  Chauhan et al., “(Competitive/benchmarking study on bilevel optimization),” 2024. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-10121701">
  “(IEEE paper, document ID 10121701),” 2023. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-sinha2014finding">
  Sinha et al., “Finding optimal solutions to bilevel problems using evolutionary algorithms,” 2014. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-kuo2011hybrid">
  Kuo et al., “(Hybrid bilevel evolutionary framework),” 2011. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-li2024bridging">
  Li et al., “(Bridging evolutionary algorithms and reinforcement learning for bilevel optimization),” 2024. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-acm-3638530-3648409">
  “(ACM paper),” doi: 10.1145/3638530.3648409.
</li>

<li id="ref-li2023ga">
  Li et al., “(GA for single-level reduced bilevel problems),” 2023. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-camacho2022tabu">
  Camacho et al., “(Tabu/metaheuristic for reduced bilevel formulation),” 2022. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-10899879">
  “(IEEE paper, document ID 10899879),” 2024/2025. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-yang2024bilevel">
  Yang et al., “(Bilevel reformulation survey / discussion),” 2024. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-lachhwani2022comprehensive">
  Lachhwani et al., “(Comprehensive review on bilevel/assumptions/constraint qualifications),” 2022. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-chaabani2018new">
  Chaabani et al., “(Co-evolutionary bilevel EA; E-CODBA or related),” 2018. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-8425468">
  “(IEEE paper, document ID 8425468),” 2018. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-islam2017surrogate">
  Islam et al., “(Surrogate-assisted evolutionary bilevel optimization),” 2017. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-dempe2002foundations">
  S. Dempe, <i>Foundations of Bilevel Programming</i>, 2002. (Add publisher / ISBN / link)
</li>

<li id="ref-sinha2017_bleaq">
  A. Sinha et al., “BLEAQ: Bilevel evolutionary algorithm based on quadratic approximations,” <i>European Journal of Operational Research</i>, 2017.
</li>

<li id="ref-8388227">
  He et al., “(Bilevel CMA-ES with distribution sharing),” 2018. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-9476019">
  Chen et al., “TLEA (transfer-learning-based parallel bilevel EA),” 2021. (Add full bibliographic details / DOI / link)
</li>

<li id="ref-9721406">
  “BLMOCC (bilevel multiobjective cooperative coevolution),” 2022. (Add full bibliographic details / DOI / link)
</li>



          
        </ol>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="muted">© <span id="year"></span> BLO Hub · Built on GitHub Pages</div>
      </div>
    </footer>
  </main>

  <script src="assets/app.js"></script>
</body>
</html>

